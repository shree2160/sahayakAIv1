# ğŸ™ Sahayak AI - Voice-Enabled Local Assistant for India

A voice-first, location-aware AI assistant designed for Indian users to solve everyday problems like mobile recharge, government forms, finding nearby services, and understanding local procedures.

![Sahayak AI](https://img.shields.io/badge/Made%20with-â¤ï¸%20for%20India-orange)
![Python](https://img.shields.io/badge/Python-3.10+-blue)
![License](https://img.shields.io/badge/License-MIT-green)

## âœ¨ Features

- ğŸ¤ **Voice Input** - Speak in Hindi or English
- ğŸ¤– **AI-Powered** - Uses Gemini AI for intelligent responses
- ğŸ“ **Location-Aware** - Find nearby hospitals, banks, offices
- ğŸ“‹ **Process Guidance** - Step-by-step help for Aadhaar, PAN, etc.
- ğŸ”Š **Voice Response** - Answers spoken back to you
- ğŸ’¯ **100% Free** - Uses only free APIs and tools
- ğŸŒ **Offline STT** - VOSK for offline speech recognition

## ğŸ—ï¸ Architecture

```
User (Browser)
  â†’ Frontend (Voice UI)
  â†’ FastAPI Backend
      â†’ VOSK (Speech-to-Text, offline)
      â†’ Gemini (AI Reasoning)
      â†’ Supabase (Local knowledge)
      â†’ OpenStreetMap (Nearby places)
      â†’ eSpeak NG (Text-to-Speech)
  â†’ Audio + Text response
```

## ğŸ“ Project Structure

```
sahayak-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ config.py            # Configuration & env vars
â”‚   â”œâ”€â”€ schemas.py           # Pydantic models
â”‚   â”œâ”€â”€ speech_to_text.py    # VOSK STT module
â”‚   â”œâ”€â”€ text_to_speech.py    # eSpeak TTS module
â”‚   â”œâ”€â”€ reasoning.py         # Gemini AI integration
â”‚   â”œâ”€â”€ osm_service.py       # OpenStreetMap service
â”‚   â”œâ”€â”€ supabase_client.py   # Database client
â”‚   â”œâ”€â”€ location_service.py  # Location utilities
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â””â”€â”€ .env.example         # Environment template
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html           # Main UI
â”‚   â”œâ”€â”€ style.css            # Styling
â”‚   â”œâ”€â”€ app.js               # Application logic
â”‚   â””â”€â”€ recorder.js          # Audio recording
â”‚
â”œâ”€â”€ supabase_setup.sql       # Database schema
â””â”€â”€ README.md                # This file
```

## ğŸš€ Quick Start

### Prerequisites

1. **Python 3.10+**
2. **Node.js** (optional, for frontend dev server)
3. **FFmpeg** (for audio conversion)
4. **eSpeak NG** (for text-to-speech)

### 1. Clone & Setup Backend

```bash
# Clone repository
git clone https://github.com/yourusername/sahayak-ai.git
cd sahayak-ai/backend

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 2. Get Free API Keys

#### Gemini AI (Required)
1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Create a new API key
3. Copy the key

#### Supabase (Optional but recommended)
1. Go to [Supabase](https://supabase.com)
2. Create a new project
3. Go to Settings â†’ API
4. Copy the URL and `anon` key

### 3. Configure Environment

```bash
# Copy example env file
cp .env.example .env

# Edit .env with your keys
notepad .env  # Windows
# nano .env   # Linux
```

Add your keys:
```
GEMINI_API_KEY=your_gemini_key_here
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your_anon_key_here
```

### 4. Download VOSK Hindi Model

```bash
# Create models directory
mkdir vosk_models
cd vosk_models

# Download Hindi model (small version ~50MB)
# Option 1: Direct download
curl -LO https://alphacephei.com/vosk/models/vosk-model-small-hi-0.22.zip
unzip vosk-model-small-hi-0.22.zip

# Option 2: PowerShell
Invoke-WebRequest -Uri "https://alphacephei.com/vosk/models/vosk-model-small-hi-0.22.zip" -OutFile "vosk-model-small-hi-0.22.zip"
Expand-Archive -Path "vosk-model-small-hi-0.22.zip" -DestinationPath "."
```

### 5. Install System Dependencies

#### Windows
```powershell
# Install FFmpeg (using Chocolatey)
choco install ffmpeg

# Install eSpeak NG
# Download from: https://github.com/espeak-ng/espeak-ng/releases
# Run the installer
```

#### Ubuntu/Debian
```bash
sudo apt update
sudo apt install ffmpeg espeak-ng
```

#### macOS
```bash
brew install ffmpeg espeak-ng
```

### 6. Run the Backend

```bash
cd backend
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at `http://localhost:8000`

### 7. Run the Frontend

Option A: Simple HTTP Server
```bash
cd frontend
python -m http.server 3000
```

Option B: VS Code Live Server
- Install "Live Server" extension
- Right-click `index.html` â†’ "Open with Live Server"

Open `http://localhost:3000` in your browser.

## ğŸ—„ï¸ Database Setup (Supabase)

1. Go to your Supabase project dashboard
2. Navigate to SQL Editor
3. Run the contents of `supabase_setup.sql`

This creates the `local_knowledge` table with sample data.

## ğŸŒ Free Deployment

### Backend (Render)

1. Create account at [render.com](https://render.com)
2. Connect your GitHub repository
3. Create new "Web Service"
4. Configure:
   - Build Command: `pip install -r requirements.txt`
   - Start Command: `uvicorn main:app --host 0.0.0.0 --port $PORT`
5. Add environment variables from `.env`
6. Deploy!

### Frontend (Vercel)

1. Create account at [vercel.com](https://vercel.com)
2. Import your GitHub repository
3. Select `frontend` folder as root
4. Deploy!

Update `frontend/app.js` with your Render URL:
```javascript
API_BASE_URL: 'https://your-app.onrender.com'
```

## ğŸ® Usage Examples

### Voice Commands (Hindi)
- "à¤®à¥‹à¤¬à¤¾à¤‡à¤² à¤°à¤¿à¤šà¤¾à¤°à¥à¤œ à¤•à¥ˆà¤¸à¥‡ à¤•à¤°à¥‡à¤‚?"
- "à¤¨à¤œà¤¦à¥€à¤•à¥€ à¤…à¤¸à¥à¤ªà¤¤à¤¾à¤² à¤•à¤¹à¤¾à¤‚ à¤¹à¥ˆ?"
- "à¤†à¤§à¤¾à¤° à¤•à¤¾à¤°à¥à¤¡ à¤…à¤ªà¤¡à¥‡à¤Ÿ à¤•à¥ˆà¤¸à¥‡ à¤•à¤°à¥‡à¤‚?"
- "à¤ªà¥ˆà¤¨ à¤•à¤¾à¤°à¥à¤¡ à¤•à¥ˆà¤¸à¥‡ à¤¬à¤¨à¤µà¤¾à¤à¤‚?"
- "à¤ªà¤¾à¤¸à¤ªà¥‹à¤°à¥à¤Ÿ à¤•à¥‡ à¤²à¤¿à¤ à¤•à¥à¤¯à¤¾ à¤¡à¥‰à¤•à¥à¤¯à¥‚à¤®à¥‡à¤‚à¤Ÿ à¤šà¤¾à¤¹à¤¿à¤?"

### Text Commands (English/Hinglish)
- "How to recharge mobile?"
- "Where is nearest bank?"
- "Driving license kaise banaye?"

## ğŸ”§ API Endpoints

### POST /ask
Main endpoint for queries.

**Request:**
```json
{
  "audio_base64": "optional base64 audio",
  "text_query": "your question",
  "latitude": 28.6139,
  "longitude": 77.2090,
  "language": "hi"
}
```

**Response:**
```json
{
  "success": true,
  "text_response": "Detailed answer...",
  "audio_base64": "base64 audio response",
  "transcribed_text": "what user said",
  "detected_intent": "mobile_recharge",
  "nearby_places": [...]
}
```

### GET /health
Check service status.

## ğŸ› Troubleshooting

### VOSK not loading
- Ensure model is extracted to `backend/vosk_models/vosk-model-small-hi-0.22/`
- Check model name in `.env` matches folder name

### eSpeak not found
- Verify installation: `espeak-ng --version`
- Add to PATH if needed

### FFmpeg errors
- Install FFmpeg and add to PATH
- Verify: `ffmpeg -version`

### CORS errors
- Check `ALLOWED_ORIGINS` in `config.py`
- Ensure frontend URL is listed

## ğŸ“ License

MIT License - feel free to use for your projects!

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Submit a pull request

## ğŸ™ Acknowledgments

- [VOSK](https://alphacephei.com/vosk/) - Offline speech recognition
- [eSpeak NG](https://github.com/espeak-ng/espeak-ng) - Text-to-speech
- [Google Gemini](https://deepmind.google/technologies/gemini/) - AI reasoning
- [OpenStreetMap](https://www.openstreetmap.org/) - Map data
- [Supabase](https://supabase.com) - Database

---

**Made with â¤ï¸ for India**
